version: '3.8'
services:
  llm_runtime:
    build: 
      context: ./
      dockerfile: ./DockerfileCPU
    image:
      bureaucratschoice/dckr_llm:dev-llm_runtime_cpu
    environment:
      - MODEL=value
      - HOST=0.0.0.0
      - PORT=80
    command: ["python3", "-m", "llama_cpp.server"]





